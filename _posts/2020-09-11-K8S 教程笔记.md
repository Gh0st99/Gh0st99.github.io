---
layout: post
title:  "K8S 教程记录"
date:   2020-09-09 16:01:13 +0800
categories: Java
---


# Docker

```bash
docker top db
```

- `PID`: Process ID;
- `PPID`: Parent Process ID。

```bash
pgrep <program>
```

获取 `program` 进程号。

```bash
cat /proc/$PID/environ
# 一样
docker exec -it <program> env
```

---

## 命名空间

命名空间限制了进程可以看到以及可以访问系统的特定部分（其他网络接口以及进程）。

当容器启动，`container runtime` e.g. `Docker`，会创建新的 **命名空间** 来沙箱进程。

进程跑在自己 `Pid namespace`，就像系统上只有这一个进程一样。

- Mount (mnt)
- Process ID (pid)
- Network (net)
- Interprocess Communication (ipc)
- UTS (hostnames)
- User ID (user)
- Control group (cgroup)


`unshare` 和 `nsenter` 可以用来

---

## Chroot
- 容器进程的最重要的部分是独立于 `host` 的不同文件；
- 给进程提供了相对于宿主 `OS` 不同的 `root` 目录，这允许了 上面的1；


---

## CGroup
- 限制了进程能 `consume` 的资源量； `/proc` 目录下，映射到 `/sysfs/cgroup/` 目录；
- 所有 `docker` 内存在：`/sys/fs/cgroup/memory/docker/`。

### 限制内存使用

修改
```bash
echo 8000000 > /sys/fs/cgroup/memory/docker/$DBID/memory.limit_in_bytes
```

查看
```bash
docker stats db --no-stream
```

---

## Contiainer

### image
`container image` 是
- 包含了 `tar files` 的 `tar file`；
- `files` + `metadata`；
  - metadata:
    - author；
    - 启动的 `command`；
    - 设置的 `environment variables` 等；
- 这些文件组成了我们容器的 `root filesystem`；
- 由 `layers` 组成，概念上堆叠起来；
- 每个 `layer` 可增加、删除、修改 `file` 和 `metadata`；
- 共享 `layer` 优化磁盘使用、传输时间以及内存使用。

```bash
docker save image > image.tar
```

`busy-box` 安装。

**空 `image`**
```bash
tar cv --files-from /dev/null | docker import - empty
```

**空 image** 叫 `scratch`，允许从 `scratch` 上构建。
使用 `docker import` 加载 `tarball` 到 `docker`。

**`docker commit`** 

保存 `container` 的所有变化到新的 `layer`，创建新的 `image`。

**`docker build`**
优先用这种。

`low` 方式：
```bash
docker run -it ubuntu
# in ubuntu
apt-get update && apt-get install figlet
# out ubuntu
docker diff <ubuntu container id|name>
docker commit <ubuntu container id|name> <newImageId>
docker tag <newImageId> figlet
```

**image namespace**

- 官方镜像 e.g. `ubuntu`;
- 用户或组织镜像 e.g. `jpetazzo/clock`；
- 自供 `docker.elastic.co/elasticsearch/elasticsearch:7.9.1-arm64`


---

### layer

![read-write-layer]({{ site.url }}/assets/imgs/k8s/rw-layer.png)

---

### containers vs. images

- `image`: 只读文件系统；
- `container`: 封装的一系列进程；跑在上面的只读文件系统的副本中；
- 使用了 `copy-on-write` 代替普通的 `copy`。

![multi-layers]({{ site.url }}/assets/imgs/k8s/multi-layers.png)

---

### 部署第一个 container

```bash
docker run -d image
```

---

#### 查看
```bash
# 所有
docker ps
# 查看详情
docker insepct <container-id>
# 查看日志
docker logs <container-id>
```

---

### 停止

```bash
# 立即杀死
docker kill <container id|name> ...
# 发 TREM 信号， 10s 后发 KILL
docker stop <container id|name>
```

---

### 端口映射
```bash
# 6379 到随机端口
docker run -d --name redisDynamic -p 6379 redis:latest
# 查看映射出来的端口
docker port redisDynamic 6379
```

---

### 目录映射
```bash
docker run -d --name redisMapped -v <host-dir>:<contiainer-dir> redis
# e.g.
docker run -d --name redisMapped -v /opt/docker/data/redis:/data redis
```

---

### 前台跑

```bash
# 跑 ubuntu 并且执行 ps 命令
docker run ubuntu ps
# 进入容器访问 bash shell
docker run -it ubuntu bash
# -i: 我们与容器 stdin 连接
# -t: 我们想要一个 psedo-terminal(伪终端)
```

---

### 编写第一个 Dockerfile

```dockerfile
FROM nginx:alpine
COPY . /usr/share/nginx/html
```
```bash
docker build -t webserver-image:v1 .

docker run -d -p 80:80 webserver-image:v1
```

```Dockerfile
# 比上面多启动 nginx
FROM nginx:1.11-alpine
COPY index.html /usr/share/nginx/html/index.hml
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

#### CMD & ENTRYPOINT
`UNIX` 中开始新的程序：
- `fork()` 创建子进程；
- `execve()` 替换新的子进程运行。
  - `execve(program, [list, of, arguments])`；
  - `sh -c` 就是用 `shell` 来分割命令参数。

```dockerfile
# 这里还是用 sh，但是 figlet PID = 1
# figlet 开始时，sh 被替换
CMD exec figlet -f script hello
```

- `CMD` 定义了一个默认执行的指令（如果没有的话）；
- 能在文件的**任何位置**；
- 后面的 `CMD` 会替换前面的；多条没有用。


```dockerfile
FROM ubuntu
RUN apt-get update
RUN ["apt-get", "install", "figlet"]
# 定义了 base 指令以及参数
# 命令行参数加在这些后面
ENTRYPOINT ["figlet", "-f", "script"]
```
执行下面命令：

```bash
docker run figlet salut
# 等同于
sh -c "figlet -f script" salut
```

`CMD` + `ENTRYPOINT`:

```dockerfile
ENTRYPOINT ["figlet", "-f", "script"]
# 当命令行没有参数，CMD 添加在后面，否则被替代
CMD ["hello world"]
```
---

### node.js

```Dockerfile
FROM node:10-alpine

RUN mkdir -p /src/app

WORKDIR /src/app

COPY package.json /src/app/package.json
RUN npm install

COPY . /src/app

EXPOSE 3000

CMD ["npm", "start"]
```

```bash
# -e 设置环境变量
docker run -d --name my-production-running-app -e NODE_ENV=production -p 3000:3000 my-nodejs-app
```

---

### OnBuild

---

### ignore file

`.dockerignore` 文件放入不打进容器的文件列表。

---

### Data Container

唯一用于 存放、管理数据。

```bash
# 创建一个 data container
docker create -v /config --name dataContainer busybox

# 复制到 data container 中
docker cp config.conf dataContainer:/config/

# --volumes-from 
docker run --volumes-from dataContainer ubuntu ls /config
```

导入、导出 `data container`

```bash
docker export dataContainer > dataContainer.tar
docker import dataContainer.tar
```

---

### link 连接网络

`--link <container-name|id>:<alias>` 

做两件事：
- 基于连接的容器设置环境变量，可以通过名字来引用端口、IP 等信息；
- 更新 `HOSTS` 文件

#### 修改 environment variables
```bash
# e.g. alpine env 命令会输出所有 environment variables
docker run --link redis-server:redis alpine env
```
输出：
```
REDIS_PORT=tcp://172.18.0.2:6379
REDIS_PORT_6379_TCP=tcp://172.18.0.2:6379
REDIS_PORT_6379_TCP_ADDR=172.18.0.2
REDIS_PORT_6379_TCP_PORT=6379
REDIS_PORT_6379_TCP_PROTO=tcp
REDIS_NAME=/elastic_sammet/redis
REDIS_ENV_GOSU_VERSION=1.10
REDIS_ENV_REDIS_VERSION=4.0.11
REDIS_ENV_REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-4.0.11.tar.gz
REDIS_ENV_REDIS_DOWNLOAD_SHA=fc53e73ae7586bcdacb4b63875d1ff04f68c5474c1ddeda78f00e5ae2eed1bbb
```

#### 修改 hosts
```
#               alias 原始名称 hash-id
172.18.0.2      redis bac813a4509b redis-server
```

---

### Networks

```bash
# 创建 network
docker network create backend-network
# 容器使用 network
docker run -d --name=redis --net=backend-network redis
```

- **环境变量**和 `HOSTS` 都不会增加其他容器的信息；
- 使用 `Docker` 内置 `DNS`， `resolv.conf` 中 `nameserver` 设置为 `127.0.0.11`。

```bash
# 查看所有网络
docker network ls
# 查看某网络详情
docker network inspect frontend-network
# 网络断连
docker network disconnect frontend-network redis
```

或者使用

```bash
# 创建网络
docker network create frontend-network
# connect 已有的容器到网络
docker network connect frontend-network redis

# alias 
docker network create frontend-network2
docker network connect --alias db frontend-network2 redis
# 这里 ping db 可行
docker run --net=frontend-network2 alpine ping -c1 db
```

---

### Volumes

为了共享数据将宿主机的目录映射到容器。**双向**的。

```
# ro: read only
-v <host-dir>:<container-dir>[:ro]
--volues-from <container-name|id>
```

---

### Log Files

容器启动，`Docker` 会跟踪**标准输出**和**标准错误**。

```bash
docker logs <container-name|id>
```

默认以 `json 文件` 存储。可替换为：

- Syslog：写入主机的 `central syslog`
- None: 关闭

```bash
docker run --log-driver=syslog <container>
```

---

### 重启策略

`Docker` 认为任何以**非 0 状态退出**都是 `crash`，默认 `crash container` 保持停止。

```bash
# 有限次数重启
docker run --restart-on-failure:<num> <container>
# 一直重启
docker run --restart=always <container>
```

---

### 元数据和标签

推荐格式：
- 使用 `reverse DNS` 方式: `io.github.gh0st99`；
- 小写；
- [a-z0-9-.]

```bash
# 加一个标签
docker -l key=value
# 从文件加入
docker -label-file=<label file path>

# 通过标签过滤 container
docker ps --filter "label=key=value"
docker images --filter "label=key=value"

# 给 docker 加标签
docker -d \
  -H unix:///var/run/docker.sock \
  --label com.katacoda.environment="production" \
  --label com.katacoda.storage="ssd"
```

```dockerfile
LABEL vendor=Gh0st99
LABEL io.github.gh0st99.version=0.0.1\io.github.gh0st99.build-date=2020-09-15:09:29:46z
```
---

### 负载均衡容器

容器互相交流有两种方式:
- 修改 `environment variables` 和 `hosts` 文件；
- 使用 `Service Discovery` 模式。
  - 使用三方系统识别目标系统的位置。

#### Nginx Proxy

---

### docker compose

---

### docker stats

```bash
# 单一
docker stats <container name|id>
# 所有运行
docker ps -q | xargs docker stats
```

### docker multi-stage builds

```dockerfile
# 第一阶段， 准备 Go 环境，编译 binary
FROM golang:1.6-alpine

RUN mkdir /app
ADD . /app/
WORKDIR /app
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .

# 第二阶段，把第一阶段产物复制过来
FROM alpine
EXPOSE 80
CMD ["/app"]

# 将第一阶段生成的 main 复制到根目录改名 app
COPY --from=0 /app/main /app
```

```dockerfile
# 第一阶段昵称 compiler
FROM ubuntu AS compiler
RUN apt-get update
RUN apt-get install -y build-essential
COPY hello.c /
RUN make hello

FROM ubuntu
# 将第一阶段的 hello 复制到本阶段
COPY --from=compiler /hello /hello
CMD /hello
```

运行：
```bash
docker build -t hellomultistage .
docker run hellomultistage
# 打中间状态的 image
docker build --stage compiler --tag hellocompiled
```

- `Dockerfile` 每一行创建一个新 `layer`；
- 联合 `&&` 以及 `\`。

---

### 优化 dockerfile

#### 善用 COPY
```dockerfile
FROM python
# 这里使用 COPY 创建 layer，能更有效缓存
COPY requirements.txt /tmp/requirements.txt
# 只有 requirements.txt 变时才 install
RUN pip install -qr /tmp/requirements.txt
WORKDIR /src
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]
```

#### chown，chomd，mv 要小心

- layers **无法有效**的存储**权限**和**所有者**的改变；
- 对于 `mv` 也一样；
- 所以这些指令在 `RUN` 之后都会拷贝整个文件。

```dockerfile
COPY some-file .
# 拷贝 some-file
RUN chown www-data:www-data some-file
# 拷贝 some-file
RUN chmod 644 some-file
# 拷贝 some-file
RUN mv some-file /var/www
```

解决之道：
- 使用一个 `layer` 解决；
- 使用 `COPY --chown=user:group src dest`；
  - `user` 必须在 `/etc/passwd` 或 `/etc/group` 中。
- 在本地设置好文件权限，`COPY` 会保留。
---

### 美化输出

```bash
docker ps --format '{{.Names}} container is using {{.Image}} image'
docker ps -q | xargs docker inspect --format '{{ .Id }} - {{ .Name }} - {{ .NetworkSettings.IPAddress }}'
```

---

# K8S 教程

## 部署应用

```bash
kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1
```

创建一个 `deployment`：

- 找一个应用实例能运行的合适的节点；
- scheduled 应用使其在那个 `Node` 上跑；
- 配置集群当需要的时候将实例编排到新 `Node` 上。

`K8S` 中跑的 `Pods` 跑在 私有隔离的网络上。
- 默认对同 `K8S 集群` 上其他 `Pods` 和 `services` 可见；
- 这个网络外的不可见。

```bash
kubectl proxy
```

会创建一个 `terminal` 到 `K8S 集群` 的连接。**终端可以直连到 API**。

通过 `proxy endpoint` 可以看见这些 `APIs`。e.g.

```bash
curl http://localhost:8001/version
```

`API Server` 基于 `pod name` 自动为每个 `Pod` 创建一个 `endpoint`。

---

## 查看 pod 和工作节点

`Pod`：表示一组一个或多个**应用程序容器**，以及这些容器的一些共享资源：

- 共享存储，当作卷；
- 网络，作为唯一的集群 IP 地址；
- 有关每个容器如何运行的信息(e.g. port, version)。

`Pod`： 
- 逻辑主机；
- 共享 `IP & Port`；
- 平台原子单元；
- 创建 `Deployment`，会在其中创建包含容器的 `Pod`；
  - 每个 `Pod` 与**调度它的工作节点绑定**直到，直到终止；
  - 如果 `Node` 出现问题，则在其他可用 `Node` 调度相同的 `Pod`。

**工作节点**：

**主节点**管理**工作节点**，**工作节点**有多个 `Pod`。

**主节点**自动处理集群中**工作节点**调度 `pod`。